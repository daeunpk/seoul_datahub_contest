{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b9eb3a",
   "metadata": {},
   "source": [
    "\n",
    "# 서울 공원·산 블로그 데이터 — 문장 기반 필터링 + 딥러닝 감성분석 (ipynb)\n",
    "**핵심 아이디어**  \n",
    "1) 문장 단위로 분리 → 2) 공원/산 관련 문장만 선별(고정 엔티티 매칭, 선택: 임베딩 유사도) →  \n",
    "3) 해당 문장만 딥러닝 모델에 입력(Transformers) → 4) 엔티티별 긍/부정 집계\n",
    "\n",
    "**토큰화 전략 요약**\n",
    "- **문장 토큰화**: `kss`로 한국어 문장 분리(권장).  \n",
    "- **클린업 전처리**: URL/이모지/HTML/반복문자/제휴문구 제거.  \n",
    "- **서브워드 토큰화**: 감성모델의 **동일 토크나이저**(예: KcELECTRA/KoBERT tokenizer) 사용.  \n",
    "- (선택) **형태소 토큰화**는 키워드 분석 보조용으로만 사용.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3f8e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "# ===== 경로 설정 =====\n",
    "INPUT_PATH  = \"crawling/naver_blog_reviews_removed_final.csv\"\n",
    "ROWLEVEL_OUT = \"/sent_by_entity_rowlevel.csv\"\n",
    "SUMMARY_OUT  = \"/sent_by_entity_summary.csv\"\n",
    "\n",
    "# ===== 모델 설정 =====\n",
    "SENT_MODEL = \"nlp04/korean_sentiment_analysis_kcelectra\"  # 한국어 감성 분석 모델 예시\n",
    "BATCH_SIZE = 32\n",
    "CONTEXT_WINDOW = 1      # 매칭 문장 앞뒤로 포함할 문맥 문장 수\n",
    "USE_EMBED_FILTER = False # True로 두면 임베딩 유사도 필터 사용(옵션)\n",
    "SIM_MODEL = \"BM-K/KoSimCSE-roberta-multitask\"\n",
    "SIM_THRESHOLD = 0.35\n",
    "\n",
    "# ===== 고정 엔티티 목록 =====\n",
    "ENTITIES = [\n",
    "    \"도산근린공원\", \"율현공원\", \"경의선숲길\", \"문화비축기지\", \"올림픽공원\",\n",
    "    \"송파나루근린공원\", \"석촌호수\", \"인왕산도시자연공원\", \"인왕산\", \"낙산공원\",\n",
    "    \"북한산국립공원\", \"북한산\", \"서울로 7017\", \"남산공원\", \"용산가족공원\",\n",
    "    \"효창근린공원\", \"효창공원\", \"강서한강공원\", \"난지한강공원\", \"양화한강공원\",\n",
    "    \"망원한강공원\", \"여의도한강공원\", \"이촌한강공원\", \"반포한강공원\", \"잠원한강공원\",\n",
    "    \"뚝섬한강공원\", \"잠실한강공원\", \"광나루한강공원\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea402d34",
   "metadata": {},
   "source": [
    "\n",
    "## 1) 클린업 전처리 (노이즈 제거용 토큰화)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd6e51e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EMOJI_PATTERN = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "\n",
    "URL_PATTERN = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "HTML_TAG = re.compile(r\"<[^>]+>\")\n",
    "MULTISPACE = re.compile(r\"\\s{2,}\")\n",
    "REPEAT_CHAR = re.compile(r\"(.)\\1{2,}\")  # 같은 문자 3회 이상 반복 → 2회로 축소\n",
    "\n",
    "BLOG_NOISE = [\n",
    "    \"© NAVER Corp.\", \"이웃추가\", \"공유하기\", \"광고\", \"협찬\", \"체험단\",\n",
    "    \"무단 전재\", \"리그램\", \"포스팅\", \"사진첨부\"\n",
    "]\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    t = text\n",
    "    t = HTML_TAG.sub(\" \", t)\n",
    "    t = URL_PATTERN.sub(\" \", t)\n",
    "    t = EMOJI_PATTERN.sub(\" \", t)\n",
    "    for noise in BLOG_NOISE:\n",
    "        t = t.replace(noise, \" \")\n",
    "    t = REPEAT_CHAR.sub(r\"\\1\\1\", t)   # ㅋㅋㅋㅋ → ㅋㅋ\n",
    "    t = re.sub(r\"[\\r\\t]+\", \" \", t)\n",
    "    t = MULTISPACE.sub(\" \", t).strip()\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be8d63",
   "metadata": {},
   "source": [
    "\n",
    "## 2) 문장 토큰화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5598ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    import kss\n",
    "    def sent_splitter(text: str):\n",
    "        try:\n",
    "            sents = kss.split_sentences(text)\n",
    "            return [s.strip() for s in sents if s and s.strip()]\n",
    "        except Exception:\n",
    "            pass\n",
    "except Exception:\n",
    "    kss = None\n",
    "\n",
    "import re as _re\n",
    "def regex_sentence_split(text: str):\n",
    "    t = _re.sub(r\"[\\r\\t]+\", \" \", text)\n",
    "    t = _re.sub(r\"([.!?])\", r\"\\1 \", t)\n",
    "    sents = [s.strip() for s in _re.split(r\"[\\n]+|(?<=[.!?])\\s+\", t) if s.strip()]\n",
    "    return sents\n",
    "\n",
    "if 'sent_splitter' not in globals():\n",
    "    def sent_splitter(text: str):\n",
    "        return regex_sentence_split(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e9688f",
   "metadata": {},
   "source": [
    "\n",
    "## 3) 엔티티 관련 문장 선별\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a0787a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_relevant_sentences(text: str, entity: str, context_window: int = 1) -> List[str]:\n",
    "    sents = sent_splitter(text)\n",
    "    hits = set(i for i, s in enumerate(sents) if entity in s)\n",
    "    if not hits:\n",
    "        return []\n",
    "    ctx_idx = set()\n",
    "    for i in hits:\n",
    "        for j in range(max(0, i - context_window), min(len(sents), i + context_window + 1)):\n",
    "            ctx_idx.add(j)\n",
    "    return [sents[i] for i in sorted(ctx_idx)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee3371c",
   "metadata": {},
   "source": [
    "\n",
    "### (선택) 임베딩 유사도 필터\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f7dcd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EMBEDDER = None\n",
    "if USE_EMBED_FILTER:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    EMBEDDER = SentenceTransformer(SIM_MODEL)\n",
    "\n",
    "def embed_filter(sentences: List[str], entity: str, threshold: float = 0.35) -> List[str]:\n",
    "    if not sentences or EMBEDDER is None:\n",
    "        return sentences\n",
    "    prompt = f\"{entity} 공원/산 관련 후기/시설/경관/산책/등산/접근성/혼잡도/청결/안전/만족도\"\n",
    "    q = EMBEDDER.encode([prompt], convert_to_tensor=True, normalize_embeddings=True)\n",
    "    c = EMBEDDER.encode(sentences, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    sims = (q @ c.T).squeeze(0)  # cosine\n",
    "    return [s for s, sim in zip(sentences, sims) if float(sim) >= threshold]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a042bd23",
   "metadata": {},
   "source": [
    "\n",
    "## 4) 데이터 로드 → 클린업 → 문장 선별\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba4de1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Kss]: Because there's no supported C++ morpheme analyzer, Kss will take pecab as a backend. :D\n",
      "For your information, Kss also supports mecab backend.\n",
      "We recommend you to install mecab or konlpy.tag.Mecab for faster execution of Kss.\n",
      "Please refer to following web sites for details:\n",
      "- mecab: https://github.com/hyunwoongko/python-mecab-kor\n",
      "- konlpy.tag.Mecab: https://konlpy.org/en/latest/api/konlpy.tag/#mecab-class\n",
      "\n",
      "/Users/daeunpark/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/pecab/_tokenizer.py:265: RuntimeWarning: overflow encountered in scalar add\n",
      "  from_pos_data.costs[idx]\n",
      "/Users/daeunpark/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/pecab/_tokenizer.py:274: RuntimeWarning: overflow encountered in scalar add\n",
      "  least_cost += word_cost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선별된 행 수: 514\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_query</th>\n",
       "      <th>entity</th>\n",
       "      <th>relevant_text</th>\n",
       "      <th>content_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>도산근린공원 후기</td>\n",
       "      <td>도산근린공원</td>\n",
       "      <td>도산근린공원 서울 도심의 숨겨진 명소 도산공원 나들이 복잡한 서울 도심 한복판 쾌적...</td>\n",
       "      <td>도산근린공원 서울 도심의 숨겨진 명소 도산공원 나들이 복잡한 서울 도심 한복판 쾌적...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>도산근린공원 후기</td>\n",
       "      <td>도산근린공원</td>\n",
       "      <td>도산안창호선생기념사업회 도산 안창호 기념관 도산근린공원 ✔️ 관람장소 : 도산 안창...</td>\n",
       "      <td>도산안창호선생기념사업회 도산 안창호 기념관 도산근린공원 ✔️ 관람장소 : 도산 안창...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>도산근린공원 후기</td>\n",
       "      <td>도산근린공원</td>\n",
       "      <td>나는 압구정 로데오역 5번 출구에서 걸어왔다. 공원의 사진들 도산근린공원 소개 이 ...</td>\n",
       "      <td>방문 계기 및 위치 50m 도산공원 서울특별시 강남구 도산대로45길 20 도산전시관...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  search_query  entity                                      relevant_text  \\\n",
       "0    도산근린공원 후기  도산근린공원  도산근린공원 서울 도심의 숨겨진 명소 도산공원 나들이 복잡한 서울 도심 한복판 쾌적...   \n",
       "1    도산근린공원 후기  도산근린공원  도산안창호선생기념사업회 도산 안창호 기념관 도산근린공원 ✔️ 관람장소 : 도산 안창...   \n",
       "2    도산근린공원 후기  도산근린공원  나는 압구정 로데오역 5번 출구에서 걸어왔다. 공원의 사진들 도산근린공원 소개 이 ...   \n",
       "\n",
       "                                       content_clean  \n",
       "0  도산근린공원 서울 도심의 숨겨진 명소 도산공원 나들이 복잡한 서울 도심 한복판 쾌적...  \n",
       "1  도산안창호선생기념사업회 도산 안창호 기념관 도산근린공원 ✔️ 관람장소 : 도산 안창...  \n",
       "2  방문 계기 및 위치 50m 도산공원 서울특별시 강남구 도산대로45길 20 도산전시관...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(INPUT_PATH)\n",
    "\n",
    "needed_cols = {\"search_query\", \"content\"}\n",
    "missing = needed_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"입력 CSV에 필요한 컬럼이 없습니다: {missing}\")\n",
    "\n",
    "rows = []\n",
    "for _, r in df.iterrows():\n",
    "    content_raw = str(r[\"content\"])\n",
    "    content = clean_text(content_raw)\n",
    "    search_q = str(r[\"search_query\"])\n",
    "    for entity in ENTITIES:\n",
    "        if (entity in search_q) or (entity in content):\n",
    "            sents = extract_relevant_sentences(content, entity, context_window=CONTEXT_WINDOW)\n",
    "            sents = embed_filter(sents, entity, threshold=SIM_THRESHOLD) if USE_EMBED_FILTER else sents\n",
    "            if sents:\n",
    "                rows.append({\n",
    "                    \"search_query\": search_q,\n",
    "                    \"entity\": entity,\n",
    "                    \"relevant_text\": \" \".join(sents),\n",
    "                    \"content_clean\": content\n",
    "                })\n",
    "\n",
    "df_ex = pd.DataFrame(rows)\n",
    "print(f\"선별된 행 수: {len(df_ex)}\")\n",
    "df_ex.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad0af6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장 완료: selected_sentences.csv (총 514행)\n"
     ]
    }
   ],
   "source": [
    "# 선별 결과 CSV 저장\n",
    "OUTPUT_PATH = \"selected_sentences.csv\"  # 원하는 파일명\n",
    "df_ex.to_csv(OUTPUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"저장 완료: {OUTPUT_PATH} (총 {len(df_ex)}행)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bd9609",
   "metadata": {},
   "source": [
    "\n",
    "## 5) 딥러닝 감성분석 (Transformers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b7ea20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daeunpark/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (529) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(texts), BATCH_SIZE):\n\u001b[32m     21\u001b[39m     batch = texts[i:i+BATCH_SIZE]\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     outs = \u001b[43mclf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m outs:\n\u001b[32m     24\u001b[39m         lab = normalize_label(o[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:168\u001b[39m, in \u001b[36mTextClassificationPipeline.__call__\u001b[39m\u001b[34m(self, inputs, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[33;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[32m    135\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    165\u001b[39m \u001b[33;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    167\u001b[39m inputs = (inputs,)\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[32m    170\u001b[39m _legacy = \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/transformers/pipelines/base.py:1439\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1435\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[32m   1436\u001b[39m     final_iterator = \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   1437\u001b[39m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[32m   1438\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1439\u001b[39m     outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1440\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m item = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:125\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m    124\u001b[39m item = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    128\u001b[39m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/transformers/pipelines/base.py:1365\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1364\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1366\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1367\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:199\u001b[39m, in \u001b[36mTextClassificationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect.signature(model_forward).parameters:\n\u001b[32m    198\u001b[39m     model_inputs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/transformers/models/electra/modeling_electra.py:965\u001b[39m, in \u001b[36mElectraForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    957\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    958\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m    959\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m    960\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m    961\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m    962\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    963\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m discriminator_hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43melectra\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m sequence_output = discriminator_hidden_states[\u001b[32m0\u001b[39m]\n\u001b[32m    978\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.classifier(sequence_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/transformers/models/electra/modeling_electra.py:776\u001b[39m, in \u001b[36mElectraModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    772\u001b[39m     encoder_extended_attention_mask = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    774\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    782\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33membeddings_project\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    785\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.embeddings_project(hidden_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/seoul_datahub_contest/babo/lib/python3.12/site-packages/transformers/models/electra/modeling_electra.py:192\u001b[39m, in \u001b[36mElectraEmbeddings.forward\u001b[39m\u001b[34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.position_embedding_type == \u001b[33m\"\u001b[39m\u001b[33mabsolute\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    191\u001b[39m     position_embeddings = \u001b[38;5;28mself\u001b[39m.position_embeddings(position_ids)\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[43membeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\n\u001b[32m    193\u001b[39m embeddings = \u001b[38;5;28mself\u001b[39m.LayerNorm(embeddings)\n\u001b[32m    194\u001b[39m embeddings = \u001b[38;5;28mself\u001b[39m.dropout(embeddings)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (529) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "clf = pipeline(\"sentiment-analysis\", model=SENT_MODEL, device=device)\n",
    "\n",
    "def normalize_label(label: str) -> str:\n",
    "    l = label.strip().lower()\n",
    "    if l in (\"positive\", \"긍정\", \"pos\", \"1\"): return \"positive\"\n",
    "    if l in (\"negative\", \"부정\", \"neg\", \"0\"): return \"negative\"\n",
    "    return \"negative\"\n",
    "\n",
    "def to_positive_prob(label: str, score: float) -> float:\n",
    "    lab = normalize_label(label)\n",
    "    return float(score) if lab == \"positive\" else float(1.0 - score)\n",
    "\n",
    "pred_label, pred_score, pos_prob = [], [], []\n",
    "\n",
    "texts = df_ex[\"relevant_text\"].astype(str).tolist()\n",
    "for i in range(0, len(texts), BATCH_SIZE):\n",
    "    batch = texts[i:i+BATCH_SIZE]\n",
    "    outs = clf(batch)\n",
    "    for o in outs:\n",
    "        lab = normalize_label(o[\"label\"])\n",
    "        sc  = float(o[\"score\"])\n",
    "        pred_label.append(lab)\n",
    "        pred_score.append(sc)\n",
    "        pos_prob.append(to_positive_prob(lab, sc))\n",
    "\n",
    "df_ex[\"pred_label\"] = pred_label\n",
    "df_ex[\"pred_score\"] = pred_score\n",
    "df_ex[\"positive_prob\"] = pos_prob\n",
    "\n",
    "df_ex.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642b58c3",
   "metadata": {},
   "source": [
    "\n",
    "## 6) 결과 저장 & 엔티티별 집계\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91801688",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_ex.to_csv(ROWLEVEL_OUT, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "summary = (\n",
    "    df_ex.groupby(\"entity\", as_index=False)\n",
    "         .agg(\n",
    "             n_docs=(\"pred_label\", \"size\"),\n",
    "             n_positive=(\"pred_label\", lambda s: (s == \"positive\").sum()),\n",
    "             n_negative=(\"pred_label\", lambda s: (s == \"negative\").sum()),\n",
    "             positive_rate=(\"pred_label\", lambda s: (s == \"positive\").mean()),\n",
    "             mean_positive_prob=(\"positive_prob\", \"mean\"),\n",
    "         )\n",
    "         .sort_values([\"positive_rate\", \"mean_positive_prob\", \"n_docs\"],\n",
    "                      ascending=[False, False, False])\n",
    ")\n",
    "summary.to_csv(SUMMARY_OUT, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "summary.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020f2d18",
   "metadata": {},
   "source": [
    "\n",
    "## 7) 시각화 (상위 20개 긍정 비율 기준)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed68304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top = summary.head(20)\n",
    "plt.figure()\n",
    "plt.bar(top[\"entity\"], top[\"positive_rate\"])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Top-20 Positive Rate by Entity\")\n",
    "plt.ylabel(\"Positive Rate\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
